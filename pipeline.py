"""
Hip-Hop Noir: Graph ETL Pipeline Visualizer
ë¬¸ì„œê°€ ì§€ì‹ ê·¸ë˜í”„ë¡œ ë³€í™˜ë˜ëŠ” ì „ ê³¼ì •ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ëŠ” ëŒ€ì‹œë³´ë“œ
"""
import streamlit as st
import os
from dotenv import load_dotenv
from langchain_community.graphs import Neo4jGraph
from langchain_openai import ChatOpenAI
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_experimental.graph_transformers import LLMGraphTransformer
from langchain_core.documents import Document
from streamlit_agraph import agraph, Node, Edge, Config

# 1. ì„¤ì • ë° ì—°ê²°
load_dotenv()
st.set_page_config(layout="wide", page_title="Graph ETL Visualizer", page_icon="âš™ï¸")

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .stTextArea textarea {
        font-family: 'Consolas', monospace;
        font-size: 14px;
    }
    .step-header {
        background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%);
        padding: 10px 20px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .node-card {
        background-color: #f0f2f6;
        padding: 10px;
        border-radius: 5px;
        margin: 5px 0;
    }
</style>
""", unsafe_allow_html=True)

st.title("âš™ï¸ í™í•© ëŠì™€ë¥´: ê·¸ë˜í”„ êµ¬ì¶• íŒŒì´í”„ë¼ì¸ (ETL)")
st.caption("Raw Textê°€ ì§€ì‹ ê·¸ë˜í”„(Knowledge Graph)ë¡œ ë³€í™˜ë˜ëŠ” ì „ ê³¼ì •ì„ ì¶”ì í•©ë‹ˆë‹¤.")

# ì‚¬ì´ë“œë°”: DB ì—°ê²° ìƒíƒœ ë° ì„¤ì •
with st.sidebar:
    st.header("ğŸ”Œ System Status")
    
    neo4j_uri = os.getenv("NEO4J_URI")
    openai_key = os.getenv("OPENAI_API_KEY")
    
    if neo4j_uri:
        st.success("âœ… Neo4j Connected")
        st.caption(f"URI: {neo4j_uri[:30]}...")
    else:
        st.error("âŒ Missing NEO4J_URI in .env")
    
    if openai_key:
        st.success("âœ… OpenAI API Ready")
    else:
        st.error("âŒ Missing OPENAI_API_KEY in .env")
    
    if not neo4j_uri or not openai_key:
        st.warning("âš ï¸ .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”")
        st.stop()
    
    st.divider()
    
    # ëª¨ë¸ ë° ì²­í‚¹ ì„¤ì •
    st.header("âš™ï¸ Pipeline Settings")
    chunk_size = st.slider("Chunk Size (ë¬¸ì)", 100, 2000, 500, step=50)
    chunk_overlap = st.slider("Overlap (ì¤‘ë³µ)", 0, 500, 50, step=10)
    
    st.divider()
    
    # ìŠ¤í‚¤ë§ˆ ì„¤ì •
    st.header("ğŸ“ Schema Definition")
    allowed_nodes = st.multiselect(
        "í—ˆìš© ë…¸ë“œ íƒ€ì…",
        ["Rapper", "Producer", "Gang", "Event", "Location", "Person", "Label"],
        default=["Rapper", "Gang", "Event", "Location", "Person"]
    )
    
    allowed_rels = st.multiselect(
        "í—ˆìš© ê´€ê³„ íƒ€ì…",
        ["BEEF_WITH", "ATTACKED", "KILLED", "MEMBER_OF", "LOCATED_IN", "SIGNED_TO", "FOUNDED", "AFFILIATED_WITH", "FRIEND_WITH"],
        default=["BEEF_WITH", "ATTACKED", "KILLED", "MEMBER_OF", "LOCATED_IN"]
    )
    
    st.divider()
    
    # DB ê´€ë¦¬
    st.header("ğŸ—„ï¸ Database Management")
    if st.button("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ", type="secondary", use_container_width=True):
        try:
            graph = Neo4jGraph(
                url=os.getenv("NEO4J_URI"),
                username=os.getenv("NEO4J_USERNAME"),
                password=os.getenv("NEO4J_PASSWORD")
            )
            graph.query("MATCH (n) DETACH DELETE n")
            st.success("âœ… ë°ì´í„° ì‚­ì œ ì™„ë£Œ!")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜: {e}")

# ==========================================
# Step 1: ë¬¸ì„œ ì…ë ¥ (Raw Data)
# ==========================================
st.header("ğŸ“¥ Step 1: Raw Document Input")
st.caption("ë¶„ì„í•  ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”. LLMì´ ì´ í…ìŠ¤íŠ¸ì—ì„œ ì—”í‹°í‹°ì™€ ê´€ê³„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")

default_text = """1996ë…„ 9ì›” 7ì¼, ë˜í¼ íˆ¬íŒ(Tupac Shakur)ì€ ë¼ìŠ¤ë² ê°€ìŠ¤ì—ì„œ ë§ˆì´í¬ íƒ€ì´ìŠ¨ì˜ ê²½ê¸°ë¥¼ ê´€ëŒí–ˆë‹¤.
ê²½ê¸° ì§í›„, íˆ¬íŒì€ ë¡œë¹„ì—ì„œ ì˜¬ëœë„ ì•¤ë”ìŠ¨(Orlando Anderson)ì´ë¼ëŠ” 'Southside Crips' ê°±ë‹¨ì›ê³¼ ì‹¸ì›€ì„ ë²Œì˜€ë‹¤.
ëª‡ ì‹œê°„ ë’¤, íˆ¬íŒì€ ìŠˆê·¸ ë‚˜ì´íŠ¸(Suge Knight)ê°€ ìš´ì „í•˜ëŠ” ì°¨ë¥¼ íƒ€ê³  ê°€ë˜ ì¤‘ ì´ê²©ì„ ë‹¹í•´ ì‚¬ë§í–ˆë‹¤.
ë§ì€ ì‚¬ëŒë“¤ì€ ì´ ì‚¬ê±´ì´ ë™ë¶€ì˜ ë¹„ê¸°(Notorious B.I.G.)ì™€ ì—°ê´€ë˜ì–´ ìˆë‹¤ê³  ì˜ì‹¬í–ˆë‹¤."""

input_text = st.text_area(
    "ë¶„ì„í•  í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
    value=default_text,
    height=180,
    key="input_text"
)

col1, col2, col3 = st.columns([1, 1, 2])
with col1:
    run_button = st.button("ğŸš€ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", type="primary", use_container_width=True)
with col2:
    st.metric("ì…ë ¥ ë¬¸ì ìˆ˜", f"{len(input_text):,}")

if run_button:
    if not input_text.strip():
        st.error("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        st.stop()
    
    # Neo4j ë° LLM ì—°ê²°
    llm = ChatOpenAI(model="gpt-4o", temperature=0, api_key=os.getenv("OPENAI_API_KEY"))
    graph = Neo4jGraph(
        url=os.getenv("NEO4J_URI"),
        username=os.getenv("NEO4J_USERNAME"),
        password=os.getenv("NEO4J_PASSWORD")
    )

    # ==========================================
    # Step 2: ì²­í‚¹ (Chunking)
    # ==========================================
    st.divider()
    st.header("âœ‚ï¸ Step 2: Text Chunking")
    st.caption(f"ê¸´ ë¬¸ì„œë¥¼ LLMì´ ì²˜ë¦¬í•˜ê¸° ì¢‹ì€ í¬ê¸°({chunk_size}ì)ë¡œ ë¶„í• í•©ë‹ˆë‹¤.")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap
    )
    docs = [Document(page_content=input_text)]
    chunks = text_splitter.split_documents(docs)
    
    st.success(f"âœ… ì´ **{len(chunks)}ê°œ**ì˜ ì²­í¬ë¡œ ë¶„í• ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    # ì²­í¬ ì‹œê°í™”
    num_cols = min(len(chunks), 4)
    if num_cols > 0:
        cols = st.columns(num_cols)
        for i, chunk in enumerate(chunks):
            with cols[i % num_cols]:
                with st.container():
                    st.markdown(f"**ğŸ§© Chunk #{i+1}**")
                    st.caption(f"({len(chunk.page_content)} chars)")
                    preview = chunk.page_content[:150] + "..." if len(chunk.page_content) > 150 else chunk.page_content
                    st.info(f'"{preview}"')

    # ==========================================
    # Step 3: LLM íŒŒì‹± & ì¶”ì¶œ (Parsing)
    # ==========================================
    st.divider()
    st.header("ğŸ§  Step 3: LLM Entity & Relation Extraction")
    st.caption("GPT-4oê°€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì—”í‹°í‹°(ë…¸ë“œ)ì™€ ê´€ê³„(ì—£ì§€)ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
    
    with st.spinner("ğŸ¤– LLMì´ í…ìŠ¤íŠ¸ë¥¼ ì´í•´í•˜ê³  ê´€ê³„ë¥¼ ì¶”ì¶œ ì¤‘ì…ë‹ˆë‹¤... (ì•½ 10-30ì´ˆ ì†Œìš”)"):
        try:
            llm_transformer = LLMGraphTransformer(
                llm=llm,
                allowed_nodes=allowed_nodes,
                allowed_relationships=allowed_rels
            )
            graph_documents = llm_transformer.convert_to_graph_documents(chunks)
            
            # ì „ì²´ í†µê³„
            total_nodes = sum(len(doc.nodes) for doc in graph_documents)
            total_rels = sum(len(doc.relationships) for doc in graph_documents)
            
            st.success(f"âœ… ì¶”ì¶œ ì™„ë£Œ! ë…¸ë“œ: **{total_nodes}ê°œ**, ê´€ê³„: **{total_rels}ê°œ**")
            
        except Exception as e:
            st.error(f"âŒ LLM ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            st.stop()
    
    # íŒŒì‹± ê²°ê³¼ ì‹œê°í™”
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ”µ Extracted Nodes")
        all_nodes = []
        for doc in graph_documents:
            all_nodes.extend(doc.nodes)
        
        if all_nodes:
            for node in all_nodes:
                st.code(f"(:{node.type} {{id: '{node.id}'}})", language="cypher")
        else:
            st.warning("ì¶”ì¶œëœ ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.subheader("ğŸ”— Extracted Relationships")
        all_rels = []
        for doc in graph_documents:
            all_rels.extend(doc.relationships)
        
        if all_rels:
            for rel in all_rels:
                st.code(f"({rel.source.id}) -[:{rel.type}]-> ({rel.target.id})", language="cypher")
        else:
            st.warning("ì¶”ì¶œëœ ê´€ê³„ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ==========================================
    # Step 4: Cypher ì½”ë“œ ë³€í™˜
    # ==========================================
    st.divider()
    st.header("ğŸ“ Step 4: Generated Cypher Query")
    st.caption("LLMì´ ì¶”ì¶œí•œ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ë  DB ì¿¼ë¦¬ì…ë‹ˆë‹¤.")
    
    cypher_preview = "// ë…¸ë“œ ìƒì„± ì¿¼ë¦¬\n"
    for node in all_nodes:
        props = ", ".join([f"{k}: '{v}'" for k, v in node.properties.items()]) if node.properties else ""
        if props:
            cypher_preview += f"MERGE (n:{node.type} {{id: '{node.id}', {props}}})\n"
        else:
            cypher_preview += f"MERGE (n:{node.type} {{id: '{node.id}'}})\n"
    
    cypher_preview += "\n// ê´€ê³„ ìƒì„± ì¿¼ë¦¬\n"
    for rel in all_rels:
        cypher_preview += f"MATCH (a {{id: '{rel.source.id}'}}), (b {{id: '{rel.target.id}'}})\n"
        cypher_preview += f"MERGE (a)-[:{rel.type}]->(b)\n\n"
    
    st.code(cypher_preview, language="cypher")
    
    # ë³µì‚¬ ë²„íŠ¼
    st.download_button(
        label="ğŸ“‹ Cypher ì¿¼ë¦¬ ë‹¤ìš´ë¡œë“œ",
        data=cypher_preview,
        file_name="generated_cypher.cql",
        mime="text/plain"
    )

    # ==========================================
    # Step 5: DB ì €ì¥ ë° ì‹œê°í™” (Final Output)
    # ==========================================
    st.divider()
    st.header("ğŸ¨ Step 5: Final Graph Visualization")
    st.caption("Neo4jì— ì €ì¥ëœ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.")
    
    # DB ì €ì¥
    with st.spinner("ğŸ’¾ Neo4j ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ ì¤‘..."):
        try:
            graph.add_graph_documents(graph_documents)
            st.toast("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ!", icon="ğŸ’¾")
        except Exception as e:
            st.error(f"âŒ DB ì €ì¥ ì˜¤ë¥˜: {e}")
            st.stop()

    # ì‹œê°í™”ë¥¼ ìœ„í•´ DBì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    with st.spinner("ğŸ¨ ê·¸ë˜í”„ ë Œë”ë§ ì¤‘..."):
        try:
            visual_query = """
            MATCH (n)-[r]->(m)
            RETURN n, r, m
            LIMIT 100
            """
            results = graph.query(visual_query)
            
            nodes = []
            edges = []
            node_ids = set()
            
            # ë…¸ë“œ íƒ€ì…ë³„ ìƒ‰ìƒ ì •ì˜
            color_map = {
                "Rapper": "#FF6B6B",      # ë¹¨ê°„ìƒ‰
                "Producer": "#4ECDC4",    # ì²­ë¡ìƒ‰
                "Gang": "#45B7D1",         # íŒŒë€ìƒ‰
                "Event": "#96CEB4",        # ì—°ë‘ìƒ‰
                "Location": "#FFEAA7",     # ë…¸ë€ìƒ‰
                "Person": "#DDA0DD",       # ë³´ë¼ìƒ‰
                "Label": "#F39C12"         # ì£¼í™©ìƒ‰
            }

            for record in results:
                source = record['n']
                target = record['m']
                rel = record['r']
                
                # ì†ŒìŠ¤ ë…¸ë“œ
                src_id = source.get('id', source.get('name', str(id(source))))
                src_labels = list(source.labels) if hasattr(source, 'labels') else []
                src_label = src_labels[0] if src_labels else "Node"
                src_color = color_map.get(src_label, "#999999")
                
                if src_id not in node_ids:
                    nodes.append(Node(
                        id=src_id,
                        label=src_id,
                        size=25,
                        color=src_color,
                        title=f"{src_label}: {src_id}"
                    ))
                    node_ids.add(src_id)
                
                # íƒ€ê²Ÿ ë…¸ë“œ
                tgt_id = target.get('id', target.get('name', str(id(target))))
                tgt_labels = list(target.labels) if hasattr(target, 'labels') else []
                tgt_label = tgt_labels[0] if tgt_labels else "Node"
                tgt_color = color_map.get(tgt_label, "#999999")

                if tgt_id not in node_ids:
                    nodes.append(Node(
                        id=tgt_id,
                        label=tgt_id,
                        size=25,
                        color=tgt_color,
                        title=f"{tgt_label}: {tgt_id}"
                    ))
                    node_ids.add(tgt_id)
                
                # ì—£ì§€ (ê´€ê³„)
                rel_type = rel[1] if isinstance(rel, tuple) else type(rel).__name__
                edges.append(Edge(
                    source=src_id,
                    target=tgt_id,
                    label=rel_type,
                    color="#888888"
                ))

            if nodes:
                st.success(f"âœ… ê·¸ë˜í”„ ë¡œë“œ ì™„ë£Œ! ë…¸ë“œ: {len(nodes)}ê°œ, ì—£ì§€: {len(edges)}ê°œ")
                
                # ë²”ë¡€ í‘œì‹œ
                st.markdown("**ğŸ¨ Color Legend:**")
                legend_cols = st.columns(len(color_map))
                for i, (node_type, color) in enumerate(color_map.items()):
                    with legend_cols[i]:
                        st.markdown(f'<span style="color:{color}">â—</span> {node_type}', unsafe_allow_html=True)
                
                # ê·¸ë˜í”„ ì„¤ì •
                config = Config(
                    width=900,
                    height=600,
                    directed=True,
                    physics=True,
                    hierarchical=False,
                    nodeHighlightBehavior=True,
                    highlightColor="#F7A7A6",
                    collapsible=False,
                )
                
                # ê·¸ë˜í”„ ë Œë”ë§
                return_value = agraph(nodes=nodes, edges=edges, config=config)
                
            else:
                st.warning("âš ï¸ ì‹œê°í™”í•  ê·¸ë˜í”„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            st.error(f"âŒ ê·¸ë˜í”„ ì‹œê°í™” ì˜¤ë¥˜: {e}")
            st.info("Neo4jì— ë°ì´í„°ëŠ” ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. Neo4j Browserì—ì„œ ì§ì ‘ í™•ì¸í•´ë³´ì„¸ìš”.")

    # ìµœì¢… ìš”ì•½
    st.divider()
    st.header("ğŸ“Š Pipeline Summary")
    
    summary_cols = st.columns(5)
    with summary_cols[0]:
        st.metric("ğŸ“„ ì…ë ¥ ë¬¸ì", f"{len(input_text):,}")
    with summary_cols[1]:
        st.metric("âœ‚ï¸ ì²­í¬ ìˆ˜", len(chunks))
    with summary_cols[2]:
        st.metric("ğŸ”µ ë…¸ë“œ ìˆ˜", total_nodes)
    with summary_cols[3]:
        st.metric("ğŸ”— ê´€ê³„ ìˆ˜", total_rels)
    with summary_cols[4]:
        st.metric("âœ… ìƒíƒœ", "ì™„ë£Œ")
    
    st.success("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì™„ë£Œ! ì´ì œ `app.py`ë¥¼ ì‹¤í–‰í•˜ì—¬ ì§ˆë¬¸í•´ë³´ì„¸ìš”.")

