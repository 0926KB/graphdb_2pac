# -*- coding: utf-8 -*-
"""
AI ë²”ì£„ í”„ë¡œíŒŒì¼ëŸ¬ - í™•ë¥  ê¸°ë°˜ ì¶”ë¡  ì—”ì§„
ê´€ê³„ ê°€ì¤‘ì¹˜ë¥¼ ë¶„ì„í•˜ì—¬ ë²”ì¸ì¼ í™•ë¥ ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
"""
import streamlit as st
import os
from dotenv import load_dotenv
from langchain_community.graphs import Neo4jGraph
from langchain_openai import ChatOpenAI

# 1. ì„¤ì • ë° ì—°ê²°
load_dotenv()
st.set_page_config(page_title="Criminal Profiler AI", page_icon="âš–ï¸", layout="wide")

st.title("âš–ï¸ AI ë²”ì£„ í”„ë¡œíŒŒì¼ëŸ¬ (Probability Engine)")
st.markdown("""
ì´ ì—ì´ì „íŠ¸ëŠ” **ë‹¨ìˆœ ê²€ìƒ‰**ì„ ë„˜ì–´, ê·¸ë˜í”„ ë‚´ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ **ë²”ì¸ì¼ í™•ë¥ (Culpability Score)**ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
""")

# ì‚¬ì´ë“œë°” ì„¤ì •
with st.sidebar:
    st.header("ğŸ” ìˆ˜ì‚¬ ì„¤ì •")
    sensitivity = st.slider("ìˆ˜ì‚¬ ê°•ë„ (Inference Level)", 0.0, 1.0, 0.0, help="ë†’ì„ìˆ˜ë¡ ì°½ì˜ì ì¸ ì¶”ë¡ ì„ í•©ë‹ˆë‹¤.")
    
    st.divider()
    st.markdown("### ğŸ“Š ê´€ê³„ ê°€ì¤‘ì¹˜")
    st.markdown("""
    | ê´€ê³„ | ì ìˆ˜ |
    |------|------|
    | `SHOT_AT`, `KILLED` | 99% |
    | `HIRED_HITMAN`, `ORDERED_HIT` | 95% |
    | `GAVE_WEAPON`, `RODE_IN` | 70% |
    | `BEEF_WITH`, `RIVAL_OF` | 30% |
    """)
    
    st.divider()
    neo4j_uri = os.getenv("NEO4J_URI", "Not set")
    st.success(f"âœ… DB ì—°ê²°ë¨")
    st.caption(f"{neo4j_uri[:30]}...")

# 2. Neo4j & LLM ì—°ê²°
@st.cache_resource
def get_graph():
    return Neo4jGraph(
        url=os.getenv("NEO4J_URI"),
        username=os.getenv("NEO4J_USERNAME"),
        password=os.getenv("NEO4J_PASSWORD")
    )

@st.cache_resource
def get_llm(_sensitivity):
    return ChatOpenAI(model="gpt-4o", temperature=_sensitivity)

graph = get_graph()
llm = get_llm(sensitivity)

def get_evidence_from_db():
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íˆ¬íŒ ê´€ë ¨ ëª¨ë“  ì¦ê±°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    
    # íˆ¬íŒì„ í–¥í•œ ëª¨ë“  ê´€ê³„
    query1 = """
    MATCH (a)-[r]->(t)
    WHERE t.id CONTAINS 'Tupac' OR t.id CONTAINS 'tupac'
    RETURN a.id as suspect, type(r) as relation, t.id as victim
    """
    
    # Multi-hop ê´€ê³„ (A -> B -> Tupac)
    query2 = """
    MATCH path = (a)-[r1]->(b)-[r2]->(t)
    WHERE (t.id CONTAINS 'Tupac' OR t.id CONTAINS 'tupac')
    AND a.id <> b.id
    RETURN a.id as mastermind, type(r1) as relation1, b.id as middleman, type(r2) as relation2, t.id as victim
    LIMIT 20
    """
    
    # Puff Daddyì˜ ëª¨ë“  ê´€ê³„
    query3 = """
    MATCH (p)-[r]->(t)
    WHERE p.id CONTAINS 'Puff' OR p.id CONTAINS 'Diddy'
    RETURN p.id as suspect, type(r) as relation, t.id as target
    """
    
    # ëª¨ë“  ìš©ì˜ìë“¤
    query4 = """
    MATCH (a)-[r]->(t)
    WHERE (t.id CONTAINS 'Tupac' OR t.id CONTAINS 'tupac')
    AND type(r) IN ['SHOT_AT', 'KILLED', 'HIRED_HITMAN', 'ORDERED_HIT', 'OFFERED_BOUNTY', 
                    'ALLEGEDLY_ORCHESTRATED_MURDER_OF', 'GAVE_WEAPON', 'SUSPECTED_KILLER_OF']
    RETURN DISTINCT a.id as suspect, collect(DISTINCT type(r)) as relations
    """
    
    results = {
        "direct_relations": graph.query(query1),
        "multi_hop": graph.query(query2),
        "puff_daddy": graph.query(query3),
        "suspects": graph.query(query4)
    }
    
    return results

def format_evidence(evidence):
    """ì¦ê±°ë¥¼ ë¬¸ìì—´ë¡œ í¬ë§·íŒ…"""
    formatted = "=== ë°ì´í„°ë² ì´ìŠ¤ ì¦ê±° ===\n\n"
    
    formatted += "1. íˆ¬íŒì„ í–¥í•œ ì§ì ‘ ê´€ê³„:\n"
    for r in evidence["direct_relations"][:15]:
        formatted += f"   - {r['suspect']} -[:{r['relation']}]-> {r['victim']}\n"
    
    formatted += "\n2. Multi-hop ê´€ê³„ (ë°°í›„ -> ì¤‘ê°„ì -> í”¼í•´ì):\n"
    for r in evidence["multi_hop"][:10]:
        formatted += f"   - {r['mastermind']} -[:{r['relation1']}]-> {r['middleman']} -[:{r['relation2']}]-> {r['victim']}\n"
    
    formatted += "\n3. Puff Daddyì˜ ê´€ê³„:\n"
    for r in evidence["puff_daddy"][:10]:
        formatted += f"   - {r['suspect']} -[:{r['relation']}]-> {r['target']}\n"
    
    formatted += "\n4. ì£¼ìš” ìš©ì˜ì ëª©ë¡:\n"
    for r in evidence["suspects"]:
        formatted += f"   - {r['suspect']}: {r['relations']}\n"
    
    return formatted

def analyze_with_llm(question, evidence_str):
    """LLMìœ¼ë¡œ ì¦ê±°ë¥¼ ë¶„ì„í•˜ì—¬ í”„ë¡œíŒŒì¼ë§"""
    
    prompt = f"""
    ë‹¹ì‹ ì€ Neo4j ì§€ì‹ ê·¸ë˜í”„ë¥¼ ë¶„ì„í•˜ì—¬ ë²”ì¸ì„ ì§€ëª©í•˜ëŠ” 'AI ìˆ˜ì„ í”„ë¡œíŒŒì¼ëŸ¬'ì…ë‹ˆë‹¤.
    ì•„ë˜ ë°ì´í„°ë² ì´ìŠ¤ ì¦ê±°ë¥¼ ë¶„ì„í•˜ì—¬ **ë²”ì¸ì¼ í™•ë¥ **ì„ ê³„ì‚°í•˜ì„¸ìš”.

    [âš ï¸ ì¶”ë¡  ê·œì¹™ (Scoring Logic)]
    1. **ì‹¤í–‰ë²” (The Executor):** `SHOT_AT`, `KILLED`, `SUSPECTED_KILLER_OF` â†’ **í™•ë¥  99%**
    2. **ì„¤ê³„ì (The Mastermind):** `HIRED_HITMAN`, `ORDERED_HIT`, `OFFERED_BOUNTY`, `ALLEGEDLY_ORCHESTRATED_MURDER_OF` â†’ **í™•ë¥  95%**
    3. **ê³µë²” (Accomplice):** `GAVE_WEAPON`, `RODE_IN`, `ORCHESTRATED_MURDER_OF` â†’ **í™•ë¥  70%**
    4. **ë™ê¸° ë³´ìœ  (Suspect):** `BEEF_WITH`, `RIVAL_OF`, `ATTACKED` â†’ **í™•ë¥  30%**

    [ë°ì´í„°ë² ì´ìŠ¤ ì¦ê±°]
    {evidence_str}

    [ì‚¬ìš©ì ì§ˆë¬¸]
    {question}

    [ë‹µë³€ í˜•ì‹]
    ### ğŸš¨ ìœ ë ¥ ìš©ì˜ì ë¦¬í¬íŠ¸
    
    1. **[ì‹¤ì œ ì´ë¦„]** (ì—­í• : ì‹¤í–‰ë²”/ë°°í›„/ê³µë²”)
       - **ë²”í–‰ í™•ë¥ :** XX%
       - **ì¦ê±°:** ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°œê²¬ëœ ì‹¤ì œ ê´€ê³„ ì„¤ëª…
       - **ì¶”ë¡ :** ì™œ ì´ ì‚¬ëŒì´ ë²”ì¸ì¸ì§€ ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ëª…
    
    (í™•ë¥  ìˆœìœ¼ë¡œ ë‚˜ì—´)

    ---
    ### ğŸ“Š ìµœì¢… ê²°ë¡ 
    - **ì§ì ‘ ì‹¤í–‰ë²”:** [ì‹¤ì œ ì´ë¦„] (í™•ë¥  XX%)
    - **ë°°í›„ ì¡°ì¢…ì:** [ì‹¤ì œ ì´ë¦„] (í™•ë¥  XX%)
    - **ì²­ë¶€ ì²´ì¸:** A â†’ B â†’ C â†’ í”¼í•´ì (ì‹¤ì œ ì´ë¦„ìœ¼ë¡œ)
    """
    
    response = llm.invoke(prompt)
    return response.content

# 4. ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "profiler_messages" not in st.session_state:
    st.session_state["profiler_messages"] = [
        {"role": "assistant", "content": "ğŸ•µï¸â€â™‚ï¸ ì‚¬ê±´ íŒŒì¼ì„ ë¶„ì„í•  ì¤€ë¹„ê°€ ë˜ì—ˆìŠµë‹ˆë‹¤. ëˆ„êµ¬ë¥¼ í”„ë¡œíŒŒì¼ë§í• ê¹Œìš”?\n\n**ì¶”ì²œ ì§ˆë¬¸:**\n- íˆ¬íŒ ì‚¬ê±´ì˜ ë²”ì¸ê³¼ ë°°í›„ë¥¼ í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì•Œë ¤ì¤˜\n- í¼í”„ ëŒ€ë””ì˜ ë²”í–‰ í™•ë¥ ì€?\n- ì˜¬ëœë„ ì•¤ë”ìŠ¨ì€ ì™œ ìš©ì˜ìì•¼?"}
    ]

for msg in st.session_state.profiler_messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input("ì˜ˆ: íˆ¬íŒ ì‚¬ê±´ì˜ ë²”ì¸ê³¼ ë°°í›„ë¥¼ í™•ë¥  ë†’ì€ ìˆœìœ¼ë¡œ ì•Œë ¤ì¤˜"):
    st.session_state.profiler_messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("ğŸ•µï¸â€â™‚ï¸ ë°ì´í„°ë² ì´ìŠ¤ ì¡°íšŒ ì¤‘..."):
            try:
                # 1. DBì—ì„œ ì¦ê±° ìˆ˜ì§‘
                evidence = get_evidence_from_db()
                evidence_str = format_evidence(evidence)
                
                # ë””ë²„ê·¸: ì¦ê±° í‘œì‹œ
                with st.expander("ğŸ” ìˆ˜ì§‘ëœ ì¦ê±° ë³´ê¸°"):
                    st.code(evidence_str)
                
            except Exception as e:
                st.error(f"DB ì¡°íšŒ ì‹¤íŒ¨: {e}")
                st.stop()
        
        with st.spinner("ğŸ§  í”„ë¡œíŒŒì¼ë§ ë¶„ì„ ì¤‘..."):
            try:
                # 2. LLMìœ¼ë¡œ ë¶„ì„
                result = analyze_with_llm(prompt, evidence_str)
                st.markdown(result)
                st.session_state.profiler_messages.append({"role": "assistant", "content": result})
            except Exception as e:
                st.error(f"í”„ë¡œíŒŒì¼ë§ ì‹¤íŒ¨: {e}")
